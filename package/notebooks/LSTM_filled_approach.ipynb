{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill train gap and test with any primary solver (e.g. RFE) and then use LSTM to predict the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from copy import deepcopy\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../configs/')\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import utils\n",
    "import test_config as conf\n",
    "import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143:layer_train_test_set:Data used only between dates 2013-03-03 00:00:00 and 2013-07-31 23:30:00 (both inclusive).\n",
      "164:layer_train_test_set:Test interval start: 2013-05-17 19:30:00 end: 2013-06-16 19:30:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing days 30 > 21 = (0.7*30).\n",
      "Gap condition not satisfied.\n",
      "Number of missing days 24 > 21 = (0.7*30).\n",
      "Gap condition not satisfied.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7248, 12), (1441, 12), (5807, 12))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xvar = conf.variables['xvar']\n",
    "yvar = conf.variables['yvar']\n",
    "frac = 0.7    #If missing data > 48 %, find a new test window\n",
    "\n",
    "path_to_package = '/Users/pluto/Desktop/bag/tutoring/atbin/imputation/package/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent split\n",
    "full_df = pd.read_csv(path_to_package + 'data_out/Gingin_L4_processed.csv', parse_dates=['DateTime'])\n",
    "\n",
    "test_df_, train_df_ = train_test_split.layer_train_test_set(full_df, conf, missing_frac=frac)\n",
    "\n",
    "df = pd.concat([test_df_, train_df_])\n",
    "df.shape, test_df_.shape, train_df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7248, 12), (1441, 12), (5807, 12))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split same as in imputation package\n",
    "full_df = pd.read_csv(path_to_package + 'data_out/temp_full.csv', parse_dates=['DateTime'], \n",
    "            usecols= Xvar + [yvar, conf.variables['tvar'], 'Set_rank'])\n",
    "\n",
    "test_df_ = full_df[full_df['Set_rank']=='test']\n",
    "train_df_ = full_df[~(full_df['Set_rank']=='test')]\n",
    "\n",
    "df = pd.concat([test_df_, train_df_])\n",
    "df.shape, test_df_.shape, train_df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[0] == train_df_.shape[0]  + test_df_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1441 entries, 3593 to 5033\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Ta        1441 non-null   float64       \n",
      " 1   Ws        1441 non-null   float64       \n",
      " 2   Fg        1441 non-null   float64       \n",
      " 3   VPD       1441 non-null   float64       \n",
      " 4   Fn        1441 non-null   float64       \n",
      " 5   q         1441 non-null   float64       \n",
      " 6   Ts        1441 non-null   float64       \n",
      " 7   Sws       1441 non-null   float64       \n",
      " 8   EVI       1441 non-null   float64       \n",
      " 9   Set_rank  1441 non-null   object        \n",
      " 10  DateTime  1441 non-null   datetime64[ns]\n",
      " 11  Fc        1173 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(1)\n",
      "memory usage: 146.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5807 entries, 0 to 7247\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Ta        5807 non-null   float64       \n",
      " 1   Ws        5807 non-null   float64       \n",
      " 2   Fg        5807 non-null   float64       \n",
      " 3   VPD       5807 non-null   float64       \n",
      " 4   Fn        5807 non-null   float64       \n",
      " 5   q         5807 non-null   float64       \n",
      " 6   Ts        5807 non-null   float64       \n",
      " 7   Sws       5807 non-null   float64       \n",
      " 8   EVI       5807 non-null   float64       \n",
      " 9   Set_rank  5807 non-null   object        \n",
      " 10  DateTime  5807 non-null   datetime64[ns]\n",
      " 11  Fc        3945 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(1)\n",
      "memory usage: 589.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_.info(), train_df_.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling training gap and test data using primary solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Training\n",
    "# Layer 1 training parameters\n",
    "N_FOLDS = 3\n",
    "N_CALLS = 51\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "# List of models\n",
    "\n",
    "model_library = {\n",
    "    'LGBM':\n",
    "        {\n",
    "            'params_space': [Integer(2, 10, name='num_leaves'),\n",
    "                             Categorical(['regression'], name=\"objective\"),\n",
    "                             Integer(2, 10, name='min_data_in_leaf'),\n",
    "                             Real(10 ** -4, 10 ** 0, \"uniform\", name='learning_rate'),\n",
    "                             Integer(100, 500, name='n_estimators')],\n",
    "            'model_instance': lgb.LGBMRegressor(),\n",
    "            'data': 'subset1'},\n",
    "\n",
    "    'RFE':\n",
    "        {\n",
    "            'params_space': [Integer(2, 25, name='max_depth'),\n",
    "                             Integer(2, 15, name='min_samples_leaf'),\n",
    "                             Integer(2, 15, name='min_samples_split'),\n",
    "                             Integer(100, 500, name='n_estimators')],\n",
    "            'model_instance': RandomForestRegressor(),\n",
    "            'data': 'subset2'\n",
    "        },\n",
    "}\n",
    "\n",
    "solvers = ['LGBM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fc ['Ta', 'Ws', 'Fg', 'VPD', 'Fn', 'q', 'Ts', 'Sws', 'EVI']\n"
     ]
    }
   ],
   "source": [
    "print(yvar, Xvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3945 entries, 793 to 7239\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Ta        3945 non-null   float64       \n",
      " 1   Ws        3945 non-null   float64       \n",
      " 2   Fg        3945 non-null   float64       \n",
      " 3   VPD       3945 non-null   float64       \n",
      " 4   Fn        3945 non-null   float64       \n",
      " 5   q         3945 non-null   float64       \n",
      " 6   Ts        3945 non-null   float64       \n",
      " 7   Sws       3945 non-null   float64       \n",
      " 8   EVI       3945 non-null   float64       \n",
      " 9   Set_rank  3945 non-null   object        \n",
      " 10  DateTime  3945 non-null   datetime64[ns]\n",
      " 11  Fc        3945 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(1)\n",
      "memory usage: 400.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_primary = train_df_[~train_df_[yvar].isna()]\n",
    "X_train_primary = train_primary[Xvar]\n",
    "y_train_primary = train_primary[yvar]\n",
    "\n",
    "train_primary.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Sampling new data point ------\n",
      "RMSE: 3.568, R^2: 0.245, MBE: -0.141\n",
      "RMSE: 3.321, R^2: 0.306, MBE: 0.073\n",
      "RMSE: 3.455, R^2: 0.290, MBE: 0.074\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.8472670136102473, 'n_estimators': 349, 'n_jobs': -1}\n",
      "Score: 3.4483547966607095\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.018, R^2: 0.383, MBE: 0.005\n",
      "RMSE: 3.089, R^2: 0.354, MBE: 0.049\n",
      "RMSE: 2.792, R^2: 0.437, MBE: -0.079\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.27272902895065526, 'n_estimators': 291, 'n_jobs': -1}\n",
      "Score: 2.9662875669689908\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.111, R^2: 0.355, MBE: 0.023\n",
      "RMSE: 3.281, R^2: 0.319, MBE: 0.035\n",
      "RMSE: 3.385, R^2: 0.333, MBE: 0.120\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.836095155661024, 'n_estimators': 235, 'n_jobs': -1}\n",
      "Score: 3.2586259074137836\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.962, R^2: 0.394, MBE: 0.067\n",
      "RMSE: 3.100, R^2: 0.368, MBE: 0.005\n",
      "RMSE: 2.877, R^2: 0.379, MBE: 0.004\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.1404367453346039, 'n_estimators': 448, 'n_jobs': -1}\n",
      "Score: 2.9795174140682\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.085, R^2: 0.369, MBE: -0.031\n",
      "RMSE: 3.219, R^2: 0.352, MBE: -0.041\n",
      "RMSE: 3.285, R^2: 0.316, MBE: -0.016\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.6789116421659485, 'n_estimators': 388, 'n_jobs': -1}\n",
      "Score: 3.196360622074885\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.661, R^2: 0.462, MBE: 0.058\n",
      "RMSE: 3.235, R^2: 0.358, MBE: -0.095\n",
      "RMSE: 2.614, R^2: 0.462, MBE: 0.063\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.10599701642707338, 'n_estimators': 289, 'n_jobs': -1}\n",
      "Score: 2.836345837440538\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.029, R^2: 0.385, MBE: 0.073\n",
      "RMSE: 2.525, R^2: 0.483, MBE: -0.118\n",
      "RMSE: 2.817, R^2: 0.446, MBE: -0.007\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.13530465158811153, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 2.7901506641161675\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.980, R^2: 0.383, MBE: 0.030\n",
      "RMSE: 3.353, R^2: 0.299, MBE: 0.064\n",
      "RMSE: 3.166, R^2: 0.342, MBE: 0.078\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.9026082156818519, 'n_estimators': 280, 'n_jobs': -1}\n",
      "Score: 3.166428645688487\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.431, R^2: 0.297, MBE: -0.050\n",
      "RMSE: 3.329, R^2: 0.319, MBE: -0.016\n",
      "RMSE: 3.778, R^2: 0.222, MBE: -0.341\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.9698120868399743, 'n_estimators': 361, 'n_jobs': -1}\n",
      "Score: 3.5127224677443762\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.901, R^2: 0.399, MBE: -0.151\n",
      "RMSE: 3.220, R^2: 0.348, MBE: 0.036\n",
      "RMSE: 2.774, R^2: 0.431, MBE: 0.085\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.6078698856485963, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 2.965215162552036\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.711, R^2: 0.353, MBE: 0.003\n",
      "RMSE: 3.766, R^2: 0.330, MBE: 0.145\n",
      "RMSE: 3.622, R^2: 0.393, MBE: -0.148\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0001, 'n_estimators': 119, 'n_jobs': -1}\n",
      "Score: 3.6999794199742957\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.763, R^2: 0.439, MBE: 0.120\n",
      "RMSE: 2.555, R^2: 0.485, MBE: -0.012\n",
      "RMSE: 3.021, R^2: 0.404, MBE: -0.111\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 7, 'learning_rate': 0.016694982048303355, 'n_estimators': 241, 'n_jobs': -1}\n",
      "Score: 2.779861292048924\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.667, R^2: 0.475, MBE: 0.010\n",
      "RMSE: 2.799, R^2: 0.417, MBE: -0.068\n",
      "RMSE: 3.138, R^2: 0.339, MBE: 0.070\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 1.0, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 2.867808704607519\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.768, R^2: 0.373, MBE: -0.069\n",
      "RMSE: 3.614, R^2: 0.415, MBE: 0.061\n",
      "RMSE: 3.641, R^2: 0.464, MBE: 0.008\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.0001, 'n_estimators': 254, 'n_jobs': -1}\n",
      "Score: 3.6742990263353548\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.818, R^2: 0.463, MBE: 0.024\n",
      "RMSE: 3.007, R^2: 0.395, MBE: 0.119\n",
      "RMSE: 3.329, R^2: 0.406, MBE: -0.146\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.004481194710649166, 'n_estimators': 168, 'n_jobs': -1}\n",
      "Score: 3.051167833656178\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.655, R^2: 0.368, MBE: -0.002\n",
      "RMSE: 3.541, R^2: 0.411, MBE: 0.001\n",
      "RMSE: 3.737, R^2: 0.397, MBE: -0.001\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.0001, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 3.6439794307321463\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.491, R^2: 0.428, MBE: 0.022\n",
      "RMSE: 3.571, R^2: 0.386, MBE: -0.078\n",
      "RMSE: 4.004, R^2: 0.366, MBE: 0.055\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.0001, 'n_estimators': 139, 'n_jobs': -1}\n",
      "Score: 3.688413704922128\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.741, R^2: 0.444, MBE: 0.047\n",
      "RMSE: 3.026, R^2: 0.412, MBE: 0.057\n",
      "RMSE: 2.490, R^2: 0.499, MBE: -0.131\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.053918934062785924, 'n_estimators': 237, 'n_jobs': -1}\n",
      "Score: 2.7527586996287092\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.002, R^2: 0.399, MBE: -0.026\n",
      "RMSE: 2.501, R^2: 0.506, MBE: 0.054\n",
      "RMSE: 2.847, R^2: 0.414, MBE: -0.081\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.010817047219218844, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 2.783264325834878\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.644, R^2: 0.474, MBE: 0.069\n",
      "RMSE: 2.746, R^2: 0.458, MBE: 0.010\n",
      "RMSE: 2.993, R^2: 0.378, MBE: -0.070\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.1317902297906761, 'n_estimators': 116, 'n_jobs': -1}\n",
      "Score: 2.794595938579094\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.935, R^2: 0.417, MBE: -0.154\n",
      "RMSE: 3.284, R^2: 0.330, MBE: 0.168\n",
      "RMSE: 2.335, R^2: 0.510, MBE: -0.060\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.05214107556485094, 'n_estimators': 163, 'n_jobs': -1}\n",
      "Score: 2.8515896339348146\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.808, R^2: 0.413, MBE: -0.081\n",
      "RMSE: 3.201, R^2: 0.346, MBE: -0.109\n",
      "RMSE: 2.526, R^2: 0.503, MBE: 0.122\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.054831399746156216, 'n_estimators': 275, 'n_jobs': -1}\n",
      "Score: 2.84523701526693\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.689, R^2: 0.444, MBE: 0.054\n",
      "RMSE: 2.728, R^2: 0.453, MBE: -0.013\n",
      "RMSE: 3.003, R^2: 0.404, MBE: -0.033\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.013499996347270997, 'n_estimators': 202, 'n_jobs': -1}\n",
      "Score: 2.806492575531646\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.853, R^2: 0.405, MBE: 0.021\n",
      "RMSE: 2.721, R^2: 0.479, MBE: -0.006\n",
      "RMSE: 2.815, R^2: 0.428, MBE: -0.044\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.021427421323481726, 'n_estimators': 499, 'n_jobs': -1}\n",
      "Score: 2.796115109273595\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.860, R^2: 0.423, MBE: -0.058\n",
      "RMSE: 2.787, R^2: 0.394, MBE: 0.032\n",
      "RMSE: 2.963, R^2: 0.416, MBE: 0.039\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.11373351253357546, 'n_estimators': 187, 'n_jobs': -1}\n",
      "Score: 2.870125101440116\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.988, R^2: 0.386, MBE: -0.006\n",
      "RMSE: 3.126, R^2: 0.336, MBE: 0.194\n",
      "RMSE: 2.829, R^2: 0.414, MBE: -0.116\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.12485818303559486, 'n_estimators': 455, 'n_jobs': -1}\n",
      "Score: 2.981221697313838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Sampling new data point ------\n",
      "RMSE: 2.367, R^2: 0.505, MBE: -0.041\n",
      "RMSE: 3.007, R^2: 0.425, MBE: -0.081\n",
      "RMSE: 2.895, R^2: 0.423, MBE: 0.110\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.02857873416524894, 'n_estimators': 132, 'n_jobs': -1}\n",
      "Score: 2.75637120878309\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.703, R^2: 0.450, MBE: -0.153\n",
      "RMSE: 3.021, R^2: 0.403, MBE: 0.082\n",
      "RMSE: 2.632, R^2: 0.465, MBE: 0.067\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.03110790731852642, 'n_estimators': 378, 'n_jobs': -1}\n",
      "Score: 2.7853421306577033\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.914, R^2: 0.397, MBE: 0.131\n",
      "RMSE: 2.692, R^2: 0.480, MBE: -0.063\n",
      "RMSE: 2.703, R^2: 0.460, MBE: -0.035\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.026872920970838692, 'n_estimators': 349, 'n_jobs': -1}\n",
      "Score: 2.769835677691207\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.528, R^2: 0.502, MBE: 0.002\n",
      "RMSE: 2.499, R^2: 0.479, MBE: 0.064\n",
      "RMSE: 3.293, R^2: 0.355, MBE: -0.063\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.09683880431496542, 'n_estimators': 327, 'n_jobs': -1}\n",
      "Score: 2.773390727412665\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.884, R^2: 0.413, MBE: -0.094\n",
      "RMSE: 2.914, R^2: 0.406, MBE: 0.125\n",
      "RMSE: 2.602, R^2: 0.491, MBE: -0.000\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.08666046995102326, 'n_estimators': 410, 'n_jobs': -1}\n",
      "Score: 2.7999301421382525\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.924, R^2: 0.400, MBE: 0.115\n",
      "RMSE: 2.932, R^2: 0.433, MBE: -0.032\n",
      "RMSE: 2.775, R^2: 0.405, MBE: -0.107\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.09246775354569912, 'n_estimators': 431, 'n_jobs': -1}\n",
      "Score: 2.877019408204907\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.973, R^2: 0.373, MBE: -0.014\n",
      "RMSE: 2.976, R^2: 0.403, MBE: -0.141\n",
      "RMSE: 2.547, R^2: 0.494, MBE: 0.102\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.09981752899486955, 'n_estimators': 208, 'n_jobs': -1}\n",
      "Score: 2.832113466917095\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.740, R^2: 0.448, MBE: 0.056\n",
      "RMSE: 2.893, R^2: 0.414, MBE: -0.203\n",
      "RMSE: 2.705, R^2: 0.464, MBE: 0.157\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.08129961295294094, 'n_estimators': 472, 'n_jobs': -1}\n",
      "Score: 2.7793988280709363\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.733, R^2: 0.476, MBE: 0.060\n",
      "RMSE: 2.819, R^2: 0.445, MBE: 0.039\n",
      "RMSE: 2.708, R^2: 0.433, MBE: -0.048\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.07463138645153718, 'n_estimators': 270, 'n_jobs': -1}\n",
      "Score: 2.7534338653344594\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.817, R^2: 0.438, MBE: 0.105\n",
      "RMSE: 2.809, R^2: 0.418, MBE: -0.111\n",
      "RMSE: 2.824, R^2: 0.428, MBE: 0.044\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.07176461268096028, 'n_estimators': 299, 'n_jobs': -1}\n",
      "Score: 2.8165562296178837\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.569, R^2: 0.474, MBE: -0.266\n",
      "RMSE: 2.762, R^2: 0.470, MBE: 0.042\n",
      "RMSE: 3.047, R^2: 0.389, MBE: 0.224\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.07694201372230804, 'n_estimators': 273, 'n_jobs': -1}\n",
      "Score: 2.792485601991452\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.655, R^2: 0.463, MBE: 0.216\n",
      "RMSE: 2.973, R^2: 0.418, MBE: -0.008\n",
      "RMSE: 2.712, R^2: 0.446, MBE: -0.213\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.038029896023569446, 'n_estimators': 158, 'n_jobs': -1}\n",
      "Score: 2.780199837030065\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.614, R^2: 0.480, MBE: 0.032\n",
      "RMSE: 2.772, R^2: 0.423, MBE: -0.001\n",
      "RMSE: 2.943, R^2: 0.425, MBE: -0.082\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.0421849392169018, 'n_estimators': 461, 'n_jobs': -1}\n",
      "Score: 2.7764748059037623\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.809, R^2: 0.438, MBE: -0.178\n",
      "RMSE: 2.865, R^2: 0.415, MBE: 0.175\n",
      "RMSE: 2.723, R^2: 0.454, MBE: 0.020\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 7, 'learning_rate': 0.06178752292855531, 'n_estimators': 411, 'n_jobs': -1}\n",
      "Score: 2.798981711405624\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.248, R^2: 0.332, MBE: 0.018\n",
      "RMSE: 3.354, R^2: 0.339, MBE: -0.113\n",
      "RMSE: 2.715, R^2: 0.419, MBE: -0.001\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.5773437277955191, 'n_estimators': 155, 'n_jobs': -1}\n",
      "Score: 3.1057518579114927\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.205, R^2: 0.309, MBE: -0.022\n",
      "RMSE: 2.606, R^2: 0.469, MBE: 0.093\n",
      "RMSE: 3.042, R^2: 0.397, MBE: -0.075\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.3012547169675463, 'n_estimators': 412, 'n_jobs': -1}\n",
      "Score: 2.9508768019836995\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.018, R^2: 0.343, MBE: -0.103\n",
      "RMSE: 3.030, R^2: 0.392, MBE: 0.008\n",
      "RMSE: 2.838, R^2: 0.426, MBE: 0.106\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.3221614451811456, 'n_estimators': 110, 'n_jobs': -1}\n",
      "Score: 2.962244696368393\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.882, R^2: 0.411, MBE: 0.079\n",
      "RMSE: 3.058, R^2: 0.379, MBE: -0.009\n",
      "RMSE: 2.927, R^2: 0.394, MBE: -0.095\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.3472901744214653, 'n_estimators': 419, 'n_jobs': -1}\n",
      "Score: 2.955672338765769\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.720, R^2: 0.433, MBE: -0.093\n",
      "RMSE: 3.178, R^2: 0.345, MBE: -0.165\n",
      "RMSE: 3.067, R^2: 0.382, MBE: 0.196\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.3697044079116893, 'n_estimators': 140, 'n_jobs': -1}\n",
      "Score: 2.9887091615988637\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.868, R^2: 0.397, MBE: -0.017\n",
      "RMSE: 3.067, R^2: 0.368, MBE: 0.135\n",
      "RMSE: 2.975, R^2: 0.376, MBE: -0.125\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.24354981838446652, 'n_estimators': 186, 'n_jobs': -1}\n",
      "Score: 2.9697378746363565\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.971, R^2: 0.366, MBE: 0.097\n",
      "RMSE: 3.137, R^2: 0.383, MBE: -0.037\n",
      "RMSE: 3.635, R^2: 0.267, MBE: -0.087\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.6311587059812662, 'n_estimators': 244, 'n_jobs': -1}\n",
      "Score: 3.247370332052719\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.698, R^2: 0.445, MBE: 0.053\n",
      "RMSE: 2.906, R^2: 0.464, MBE: 0.042\n",
      "RMSE: 2.665, R^2: 0.444, MBE: -0.108\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.02591816355282612, 'n_estimators': 131, 'n_jobs': -1}\n",
      "Score: 2.756211636983721\n",
      "------ Sampling new data point ------\n",
      "RMSE: 3.230, R^2: 0.360, MBE: 0.170\n",
      "RMSE: 3.037, R^2: 0.389, MBE: 0.019\n",
      "RMSE: 2.578, R^2: 0.445, MBE: -0.097\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.21597370588076908, 'n_estimators': 240, 'n_jobs': -1}\n",
      "Score: 2.948279329141099\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.437, R^2: 0.512, MBE: -0.103\n",
      "RMSE: 2.913, R^2: 0.385, MBE: -0.023\n",
      "RMSE: 3.103, R^2: 0.410, MBE: 0.096\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.19568077843465037, 'n_estimators': 161, 'n_jobs': -1}\n",
      "Score: 2.81778845897119\n",
      "------ Sampling new data point ------\n",
      "RMSE: 2.971, R^2: 0.374, MBE: 0.092\n",
      "RMSE: 2.492, R^2: 0.491, MBE: -0.117\n",
      "RMSE: 3.056, R^2: 0.411, MBE: -0.032\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.18819327221595278, 'n_estimators': 374, 'n_jobs': -1}\n",
      "Score: 2.83968335151147\n",
      "Optimal parameters\n",
      "Param: num_leaves, value: 3\n",
      "Param: objective, value: regression\n",
      "Param: min_data_in_leaf, value: 3\n",
      "Param: learning_rate, value: 0.053918934062785924\n",
      "Param: n_estimators, value: 237\n"
     ]
    }
   ],
   "source": [
    "for key in solvers:\n",
    "    label = f'val_single_{key}'\n",
    "    val = deepcopy(model_library[key])\n",
    "    reg = val['model_instance']\n",
    "    params_space = val['params_space']\n",
    "\n",
    "\n",
    "    # Bayesian opt. part\n",
    "    @use_named_args(params_space)\n",
    "    def jth_objective(**params):\n",
    "        cls = reg.set_params(**params)\n",
    "        return utils.objective_core(cls, X_train_primary, y_train_primary,\n",
    "                                    label, [1,0],\n",
    "                                    nfolds=N_FOLDS, **params)\n",
    "\n",
    "\n",
    "    res = gp_minimize(jth_objective, params_space, n_calls=N_CALLS, random_state=0)\n",
    "    \"Best score=%.4f\" % res.fun\n",
    "\n",
    "    # Generating final optimized model instance\n",
    "    print(\"Optimal parameters\")\n",
    "    params = {}\n",
    "    for param, value in zip(params_space, res.x):\n",
    "        print(f\"Param: {param.name}, value: {value}\")\n",
    "        params[param.name] = value\n",
    "\n",
    "    jth_model = reg.set_params(**params)\n",
    "    jth_model.fit(X_train_primary.values, y_train_primary.values)\n",
    "\n",
    "    # Model instance for ensemble\n",
    "    model_library[key]['model_instance_single'] = jth_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for entire X\n",
    "for key in solvers:\n",
    "    val = model_library[key]\n",
    "    cls = val[f'model_instance_single']\n",
    "    df['yall_predicted'] = cls.predict(df[Xvar])\n",
    "    \n",
    "assert df['yall_predicted'].shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling test as nan so that in next step we can predict for Xtest and gaps in X_train\n",
    "# at once.\n",
    "new_yvar = yvar + '_filled'\n",
    "\n",
    "df[new_yvar] = df[yvar].copy()\n",
    "test_filter = (df['Set_rank']=='test')\n",
    "df.loc[test_filter, new_yvar] = np.nan\n",
    "\n",
    "assert test_df_.shape[0] == df[test_filter].shape[0]\n",
    "\n",
    "df[new_yvar] = df[new_yvar].fillna(df['yall_predicted'])\n",
    "df.drop(columns={'yall_predicted'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7248 entries, 3593 to 7247\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Ta         7248 non-null   float64       \n",
      " 1   Ws         7248 non-null   float64       \n",
      " 2   Fg         7248 non-null   float64       \n",
      " 3   VPD        7248 non-null   float64       \n",
      " 4   Fn         7248 non-null   float64       \n",
      " 5   q          7248 non-null   float64       \n",
      " 6   Ts         7248 non-null   float64       \n",
      " 7   Sws        7248 non-null   float64       \n",
      " 8   EVI        7248 non-null   float64       \n",
      " 9   Set_rank   7248 non-null   object        \n",
      " 10  DateTime   7248 non-null   datetime64[ns]\n",
      " 11  Fc         5118 non-null   float64       \n",
      " 12  Fc_filled  7248 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(11), object(1)\n",
      "memory usage: 792.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining data frame for scaling\n",
    "ymean, ystd = df[new_yvar].mean(), df[new_yvar].std()\n",
    "yvar_val = df[new_yvar].values\n",
    "yvar_val = (yvar_val - ymean)/ystd\n",
    "yscale = (ymean, ystd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = df['DateTime'].values\n",
    "set_rank = df['Set_rank'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(df[Xvar])\n",
    "df = pd.DataFrame.from_records(df, columns=Xvar)\n",
    "df['DateTime'] = dtime\n",
    "df['Set_rank'] = set_rank\n",
    "df[new_yvar + '_scaled'] = yvar_val\n",
    "df.sort_values('DateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7248 entries, 1441 to 7247\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Ta                7248 non-null   float64       \n",
      " 1   Ws                7248 non-null   float64       \n",
      " 2   Fg                7248 non-null   float64       \n",
      " 3   VPD               7248 non-null   float64       \n",
      " 4   Fn                7248 non-null   float64       \n",
      " 5   q                 7248 non-null   float64       \n",
      " 6   Ts                7248 non-null   float64       \n",
      " 7   Sws               7248 non-null   float64       \n",
      " 8   EVI               7248 non-null   float64       \n",
      " 9   DateTime          7248 non-null   datetime64[ns]\n",
      " 10  Set_rank          7248 non-null   object        \n",
      " 11  Fc_filled_scaled  7248 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(10), object(1)\n",
      "memory usage: 736.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (5807, 9) (5807,)\n",
      "Test data: (1441, 9) (1441,)\n"
     ]
    }
   ],
   "source": [
    "# ------- Single model run ------\n",
    "Xtrain_ = df.loc[df['Set_rank']!='test', Xvar]\n",
    "ytrain_ = df.loc[df['Set_rank']!='test', new_yvar + '_scaled']\n",
    "\n",
    "Xtest_ = df.loc[df['Set_rank']=='test', Xvar]\n",
    "ytest_ = df.loc[df['Set_rank']=='test', new_yvar + '_scaled']\n",
    "\n",
    "print('Train data:', Xtrain_.shape, ytrain_.shape)\n",
    "print('Test data:', Xtest_.shape, ytest_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with yvar = NAN removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     27
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5803, 5, 9) (5803,)\n",
      "Train on 2901 samples, validate on 2902 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 3.8783 - val_loss: 1.2637\n",
      "Epoch 2/50\n",
      " - 1s - loss: 2.6373 - val_loss: 1.2807\n",
      "Epoch 3/50\n",
      " - 1s - loss: 1.6523 - val_loss: 1.2495\n",
      "Epoch 4/50\n",
      " - 1s - loss: 1.4871 - val_loss: 1.2372\n",
      "Epoch 5/50\n",
      " - 1s - loss: 1.1922 - val_loss: 1.1988\n",
      "Epoch 6/50\n",
      " - 1s - loss: 1.0534 - val_loss: 1.1712\n",
      "Epoch 7/50\n",
      " - 1s - loss: 1.0360 - val_loss: 1.1513\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.9628 - val_loss: 1.1279\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.9092 - val_loss: 1.1023\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.8790 - val_loss: 1.0893\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.8559 - val_loss: 1.0678\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.8269 - val_loss: 1.0400\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.7925 - val_loss: 1.0204\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.7460 - val_loss: 1.0070\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.7920 - val_loss: 0.9820\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.7402 - val_loss: 0.9537\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.7323 - val_loss: 0.9403\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.7277 - val_loss: 0.9202\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.7073 - val_loss: 0.9162\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.7141 - val_loss: 0.8938\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.6741 - val_loss: 0.8737\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.6896 - val_loss: 0.8632\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.6879 - val_loss: 0.8582\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.6809 - val_loss: 0.8512\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.6593 - val_loss: 0.8356\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.6619 - val_loss: 0.8240\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.6398 - val_loss: 0.8018\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.6596 - val_loss: 0.7924\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.6486 - val_loss: 0.7942\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.6458 - val_loss: 0.7837\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.6491 - val_loss: 0.7717\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.6434 - val_loss: 0.7607\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.6309 - val_loss: 0.7555\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.6460 - val_loss: 0.7482\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.6229 - val_loss: 0.7400\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.6423 - val_loss: 0.7318\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.6074 - val_loss: 0.7189\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.6259 - val_loss: 0.7200\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.6292 - val_loss: 0.7057\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.6220 - val_loss: 0.7053\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.6115 - val_loss: 0.6973\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.6065 - val_loss: 0.6892\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.6003 - val_loss: 0.6862\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.6026 - val_loss: 0.6918\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.5975 - val_loss: 0.6840\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.6012 - val_loss: 0.6766\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.5808 - val_loss: 0.6737\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.5902 - val_loss: 0.6708\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.5992 - val_loss: 0.6684\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.5958 - val_loss: 0.6636\n",
      "RMSE: 1.071, R^2: 0.818, MBE: 0.101\n",
      "(1437, 1) (1437,)\n"
     ]
    }
   ],
   "source": [
    "# LSTM -- Single\n",
    "NSTEPS = 5\n",
    "NFEATURES = Xtrain_.shape[1]\n",
    "\n",
    "# convert into input/output sequences\n",
    "dataset_train = np.column_stack((Xtrain_, ytrain_))\n",
    "dataset_trainX, dataset_trainy = utils.split_sequences(dataset_train, NSTEPS)\n",
    "print(dataset_trainX.shape, dataset_trainy.shape)\n",
    "\n",
    "# define model\n",
    "model_lstm = Sequential()\n",
    "#model_lstm.add(LSTM(5, input_shape=(NSTEPS, NFEATURES), activation='relu', dropout=0.5, recurrent_dropout=0.5))\n",
    "model_lstm.add(Bidirectional(LSTM(5, input_shape=(NSTEPS, NFEATURES), activation='relu', dropout=0.5, recurrent_dropout=0.5)))\n",
    "#model_lstm.add(Dense(3, kernel_initializer='normal', activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='linear'))\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model_lstm.fit(dataset_trainX, dataset_trainy,\n",
    "                            validation_split=0.5, shuffle=False,\n",
    "                            epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "dataset_test = np.column_stack((Xtest_, ytest_))\n",
    "dataset_testX, dataset_testy = utils.split_sequences(dataset_test, n_steps=NSTEPS)\n",
    "yhat_test = model_lstm.predict(dataset_testX, verbose=0)\n",
    "\n",
    "metric_lstm = utils.diagnostic_stats(dataset_testy*ystd + ymean,\n",
    "                                     yhat_test.squeeze()*ystd + ymean)\n",
    "\n",
    "print(yhat_test.shape, dataset_testy.shape)\n",
    "yhat_test = np.concatenate((np.array([np.nan]*(NSTEPS-1)), yhat_test.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1441,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[test_filter, yvar + f'_predicted_test_filled_LSTM'] = yhat_test * ystd + ymean\n",
    "\n",
    "utils.SCORES['LSTM' + '_' + 'single'] = {'rmse':metric_lstm[0],\n",
    "                                          'rsqr':metric_lstm[1],\n",
    "                                          'mbe':metric_lstm[2],\n",
    "                                          'corr':metric_lstm[3],\n",
    "                                          'stddev':metric_lstm[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_single_LGBM': {'rmse': 2.83968335151147,\n",
       "  'rsqr': 0.4250878765268005,\n",
       "  'mbe': -0.01877053754209072,\n",
       "  'corr': 0.6509234707622525,\n",
       "  'stddev': 2.759883505851562},\n",
       " 'LSTM_single': {'rmse': 1.084089379496343,\n",
       "  'rsqr': 0.8127185095144449,\n",
       "  'mbe': 0.10242508023806093,\n",
       "  'corr': 0.9015090102491516,\n",
       "  'stddev': 2.2625182}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_single_LGBM</th>\n",
       "      <td>2.840</td>\n",
       "      <td>0.425</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM_single</th>\n",
       "      <td>1.084</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.902</td>\n",
       "      <td>2.263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rmse   rsqr    mbe   corr  stddev\n",
       "val_single_LGBM  2.840  0.425 -0.019  0.651   2.760\n",
       "LSTM_single      1.084  0.813  0.102  0.902   2.263"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(utils.SCORES).T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores from imputation package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val_Layer1_LGBM</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val_Layer1_RFE</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.374</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val_Layer1_SVM</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_Layer1_GP</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val_Layer1_ANN</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_Layer2_ensemble_LGBM</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_Layer2_single_LGBM</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.445</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_single_LGBM</td>\n",
       "      <td>2.744</td>\n",
       "      <td>0.455</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.674</td>\n",
       "      <td>2.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM_single</td>\n",
       "      <td>2.648</td>\n",
       "      <td>0.195</td>\n",
       "      <td>2.351</td>\n",
       "      <td>0.442</td>\n",
       "      <td>1.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Layer2_LGBM_single</td>\n",
       "      <td>2.513</td>\n",
       "      <td>0.518</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>0.719</td>\n",
       "      <td>2.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Layer2_LGBM_ensemble</td>\n",
       "      <td>2.457</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>0.731</td>\n",
       "      <td>2.528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Models   rmse   rsqr    mbe   corr  stddev\n",
       "0            val_Layer1_LGBM  0.512  0.372  0.004  0.609   0.425\n",
       "1             val_Layer1_RFE  0.510  0.374 -0.001  0.601   0.379\n",
       "2             val_Layer1_SVM  0.476  0.413  0.003  0.637   0.430\n",
       "3              val_Layer1_GP  0.466  0.365  0.035  0.603   0.355\n",
       "4             val_Layer1_ANN  0.462  0.404 -0.013  0.626   0.368\n",
       "5   val_Layer2_ensemble_LGBM  0.469  0.439  0.001  0.663   0.424\n",
       "6     val_Layer2_single_LGBM  0.459  0.445 -0.000  0.666   0.409\n",
       "7            val_single_LGBM  2.744  0.455 -0.013  0.674   2.566\n",
       "8                LSTM_single  2.648  0.195  2.351  0.442   1.072\n",
       "9         Layer2_LGBM_single  2.513  0.518 -0.237  0.719   2.444\n",
       "10      Layer2_LGBM_ensemble  2.457  0.534 -0.075  0.731   2.528"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(path_to_package + \"data_out/temp_full_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
