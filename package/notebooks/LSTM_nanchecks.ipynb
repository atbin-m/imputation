{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from copy import deepcopy\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Bidirectional\n",
    "from keras.layers import Dense\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../configs/')\n",
    "sys.path.insert(0, '../src/')\n",
    "\n",
    "import utils\n",
    "import test_config as conf\n",
    "import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "143:layer_train_test_set:Data used only between dates 2013-03-03 00:00:00 and 2013-07-31 23:30:00 (both inclusive).\n",
      "165:layer_train_test_set:Test interval start: 2013-03-20 22:00:00 end: 2013-04-19 22:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing days 30 > 21 = (0.7*30).\n",
      "Gap condition not satisfied.\n"
     ]
    }
   ],
   "source": [
    "Xvar = conf.variables['xvar']\n",
    "yvar = conf.variables['yvar']\n",
    "frac = 0.7    #If missing data > 48 %, find a new test window\n",
    "\n",
    "path_to_package = '/Users/pluto/Desktop/bag/tutoring/atbin/imputation/package/'\n",
    "\n",
    "# ----- Data preprocessing\n",
    "df = pd.read_csv(path_to_package + 'data_out/Gingin_L4_processed.csv', parse_dates=['DateTime'])\n",
    "\n",
    "test_df_, train_df_ = train_test_split.layer_train_test_set(df, conf, missing_frac=frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-36.700340106686504"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.minimum(test_df_[yvar].min(), train_df_[yvar].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_.fillna(-99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Combining data frame for scaling\n",
    "full_df = pd.concat([train_df_, test_df_])\n",
    "ymean, ystd = full_df[yvar].mean(), full_df[yvar].std()\n",
    "yvar_val = full_df[yvar].values\n",
    "yvar_val = (yvar_val - ymean)/ystd\n",
    "yscale = (ymean, ystd)\n",
    "\n",
    "setrank = full_df['Set_rank'].values\n",
    "dtime = full_df['DateTime'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "full_df = scaler.fit_transform(full_df[Xvar])\n",
    "full_df = pd.DataFrame.from_records(full_df, columns=Xvar)\n",
    "full_df['Set_rank'] = setrank\n",
    "full_df['DateTime'] = dtime\n",
    "full_df[yvar] = yvar_val\n",
    "\n",
    "full_df.sort_values('DateTime', inplace=True)\n",
    "\n",
    "# --------- Training\n",
    "# Layer 1 training parameters\n",
    "N_FOLDS = 3\n",
    "N_CALLS = 51\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "# List of models\n",
    "\n",
    "model_library = {\n",
    "    'LGBM':\n",
    "        {\n",
    "            'params_space': [Integer(2, 10, name='num_leaves'),\n",
    "                             Categorical(['regression'], name=\"objective\"),\n",
    "                             Integer(2, 10, name='min_data_in_leaf'),\n",
    "                             Real(10 ** -4, 10 ** 0, \"uniform\", name='learning_rate'),\n",
    "                             Integer(100, 500, name='n_estimators')],\n",
    "            'model_instance': lgb.LGBMRegressor(),\n",
    "            'data': 'subset1'},\n",
    "\n",
    "    'RFE':\n",
    "        {\n",
    "            'params_space': [Integer(2, 25, name='max_depth'),\n",
    "                             Integer(2, 15, name='min_samples_leaf'),\n",
    "                             Integer(2, 15, name='min_samples_split'),\n",
    "                             Integer(100, 500, name='n_estimators')],\n",
    "            'model_instance': RandomForestRegressor(),\n",
    "            'data': 'subset2'\n",
    "        },\n",
    "\n",
    "    'SVM':\n",
    "        {\n",
    "            'params_space': [Integer(2, 6, name='degree'),\n",
    "                             Categorical(['scale'], name='gamma'),\n",
    "                             Categorical(['rbf', 'poly', 'sigmoid'], name='kernel'),\n",
    "                             Real(1, 100, \"uniform\", name='C')],\n",
    "            'model_instance': SVR(),\n",
    "            'data': 'subset3'\n",
    "        },\n",
    "\n",
    "    'GP':\n",
    "        {\n",
    "            'params_space': [Categorical([None], name='kernel'),\n",
    "                             Categorical(['fmin_l_bfgs_b', 'adam'], name='optimizer'),\n",
    "                             Real(1e-4, 1, \"uniform\", name='alpha')],\n",
    "            'model_instance': GaussianProcessRegressor(),\n",
    "            'data': 'subset4'\n",
    "        },\n",
    "\n",
    "    'ANN':\n",
    "        {\n",
    "            'params_space': [Integer(2, 20, name='hidden_layer_sizes'),\n",
    "                             Categorical(['relu'], name='activation'),\n",
    "                             Categorical(['adam', 'lbfgs'], name='solver'),\n",
    "                             Real(1e-4, 1, \"uniform\", name='alpha'),\n",
    "                             Real(1e-3, 0.1, \"uniform\", name='learning_rate_init'),\n",
    "                             Categorical(['constant', 'adaptive'], name='learning_rate')],\n",
    "            'model_instance': MLPRegressor(),\n",
    "            'data': 'subset5'\n",
    "        },\n",
    "\n",
    "    'LASSO':\n",
    "        {'params_space': None, 'model_instance': Lasso(), 'data': 'subset6'}\n",
    "}\n",
    "\n",
    "solvers_layer1 = conf.solvers_layer1\n",
    "solvers_layer2 = conf.solvers_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filter = (full_df['Set_rank']=='test')\n",
    "# ------- Single model run ------\n",
    "Xtrain_bothlayers = full_df.loc[(full_df['Set_rank'] != 'test') & (~full_df[yvar].isna()), Xvar]\n",
    "ytrain_bothlayers = full_df.loc[(full_df['Set_rank'] != 'test') & (~full_df[yvar].isna()), yvar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE with yvar = NAN removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "code_folding": [
     27
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Sampling new data point ------\n",
      "RMSE: 0.550, R^2: 0.323, MBE: 0.029\n",
      "RMSE: 0.535, R^2: 0.340, MBE: 0.001\n",
      "RMSE: 0.555, R^2: 0.311, MBE: -0.034\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.8472670136102473, 'n_estimators': 349, 'n_jobs': -1}\n",
      "Score: 0.5464260565844287\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.446, R^2: 0.444, MBE: -0.002\n",
      "RMSE: 0.509, R^2: 0.394, MBE: 0.013\n",
      "RMSE: 0.468, R^2: 0.413, MBE: -0.009\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.27272902895065526, 'n_estimators': 291, 'n_jobs': -1}\n",
      "Score: 0.4743312255350361\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.596, R^2: 0.261, MBE: -0.002\n",
      "RMSE: 0.550, R^2: 0.312, MBE: 0.009\n",
      "RMSE: 0.564, R^2: 0.287, MBE: 0.003\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.836095155661024, 'n_estimators': 235, 'n_jobs': -1}\n",
      "Score: 0.5699231238328979\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.430, R^2: 0.452, MBE: 0.014\n",
      "RMSE: 0.514, R^2: 0.393, MBE: -0.008\n",
      "RMSE: 0.450, R^2: 0.465, MBE: -0.006\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.1404367453346039, 'n_estimators': 448, 'n_jobs': -1}\n",
      "Score: 0.464682273403622\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.531, R^2: 0.346, MBE: 0.044\n",
      "RMSE: 0.530, R^2: 0.318, MBE: -0.002\n",
      "RMSE: 0.532, R^2: 0.353, MBE: -0.057\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.6789116421659485, 'n_estimators': 388, 'n_jobs': -1}\n",
      "Score: 0.5307382587841339\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.407, R^2: 0.496, MBE: -0.011\n",
      "RMSE: 0.515, R^2: 0.384, MBE: 0.021\n",
      "RMSE: 0.461, R^2: 0.439, MBE: -0.012\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.10599701642707338, 'n_estimators': 289, 'n_jobs': -1}\n",
      "Score: 0.46124066464754643\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.504, R^2: 0.405, MBE: -0.021\n",
      "RMSE: 0.438, R^2: 0.476, MBE: 0.016\n",
      "RMSE: 0.415, R^2: 0.480, MBE: 0.017\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.13530465158811153, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 0.452505184055574\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.492, R^2: 0.387, MBE: -0.009\n",
      "RMSE: 0.502, R^2: 0.380, MBE: 0.002\n",
      "RMSE: 0.503, R^2: 0.367, MBE: 0.003\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.9026082156818519, 'n_estimators': 280, 'n_jobs': -1}\n",
      "Score: 0.4990077431005451\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.557, R^2: 0.332, MBE: -0.018\n",
      "RMSE: 0.581, R^2: 0.269, MBE: 0.019\n",
      "RMSE: 0.556, R^2: 0.314, MBE: -0.010\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.9698120868399743, 'n_estimators': 361, 'n_jobs': -1}\n",
      "Score: 0.5643382974053317\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.441, R^2: 0.451, MBE: 0.015\n",
      "RMSE: 0.495, R^2: 0.393, MBE: -0.009\n",
      "RMSE: 0.489, R^2: 0.400, MBE: -0.003\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.6078698856485963, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 0.47485031657055626\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.570, R^2: 0.432, MBE: 0.019\n",
      "RMSE: 0.657, R^2: 0.368, MBE: 0.014\n",
      "RMSE: 0.592, R^2: 0.394, MBE: -0.032\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0001, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.606531362372663\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.640, R^2: 0.343, MBE: 0.029\n",
      "RMSE: 0.589, R^2: 0.404, MBE: -0.017\n",
      "RMSE: 0.581, R^2: 0.429, MBE: -0.012\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0001, 'n_estimators': 257, 'n_jobs': -1}\n",
      "Score: 0.6033662170027467\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.473, R^2: 0.415, MBE: -0.023\n",
      "RMSE: 0.442, R^2: 0.444, MBE: -0.000\n",
      "RMSE: 0.499, R^2: 0.409, MBE: 0.015\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.20727119045905457, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4714497469622745\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.591, R^2: 0.343, MBE: -0.032\n",
      "RMSE: 0.627, R^2: 0.393, MBE: 0.015\n",
      "RMSE: 0.596, R^2: 0.439, MBE: 0.017\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.0001, 'n_estimators': 205, 'n_jobs': -1}\n",
      "Score: 0.6049778347521615\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.453, R^2: 0.453, MBE: -0.010\n",
      "RMSE: 0.430, R^2: 0.483, MBE: 0.032\n",
      "RMSE: 0.465, R^2: 0.439, MBE: -0.022\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.45146099837366305, 'n_estimators': 307, 'n_jobs': -1}\n",
      "Score: 0.44968029443454255\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.479, R^2: 0.394, MBE: -0.007\n",
      "RMSE: 0.512, R^2: 0.383, MBE: -0.026\n",
      "RMSE: 0.466, R^2: 0.421, MBE: -0.001\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.4456582766265663, 'n_estimators': 129, 'n_jobs': -1}\n",
      "Score: 0.48576736447631896\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.465, R^2: 0.453, MBE: 0.006\n",
      "RMSE: 0.398, R^2: 0.499, MBE: -0.003\n",
      "RMSE: 0.488, R^2: 0.415, MBE: -0.008\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.5184174797188869, 'n_estimators': 270, 'n_jobs': -1}\n",
      "Score: 0.45073331634538666\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.427, R^2: 0.495, MBE: 0.012\n",
      "RMSE: 0.451, R^2: 0.450, MBE: 0.007\n",
      "RMSE: 0.472, R^2: 0.424, MBE: -0.015\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.3719392109641651, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4500070830138391\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.516, R^2: 0.396, MBE: -0.005\n",
      "RMSE: 0.404, R^2: 0.496, MBE: -0.004\n",
      "RMSE: 0.427, R^2: 0.489, MBE: 0.010\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.7771431162700897, 'n_estimators': 456, 'n_jobs': -1}\n",
      "Score: 0.44910880734438496\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.532, R^2: 0.339, MBE: 0.001\n",
      "RMSE: 0.450, R^2: 0.439, MBE: 0.007\n",
      "RMSE: 0.473, R^2: 0.418, MBE: -0.004\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.32586951860477237, 'n_estimators': 177, 'n_jobs': -1}\n",
      "Score: 0.4850963718690103\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.540, R^2: 0.345, MBE: -0.027\n",
      "RMSE: 0.504, R^2: 0.362, MBE: 0.040\n",
      "RMSE: 0.473, R^2: 0.393, MBE: 0.001\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.3994300382839572, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.5057670486224145\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.468, R^2: 0.438, MBE: -0.005\n",
      "RMSE: 0.465, R^2: 0.432, MBE: -0.023\n",
      "RMSE: 0.438, R^2: 0.454, MBE: 0.022\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.1739248680179861, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4573835004317652\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.657, R^2: 0.375, MBE: 0.017\n",
      "RMSE: 0.585, R^2: 0.345, MBE: -0.004\n",
      "RMSE: 0.576, R^2: 0.442, MBE: -0.013\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.0001, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.6060862766792054\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.491, R^2: 0.363, MBE: -0.023\n",
      "RMSE: 0.484, R^2: 0.408, MBE: 0.004\n",
      "RMSE: 0.455, R^2: 0.454, MBE: 0.013\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.4832581525333224, 'n_estimators': 252, 'n_jobs': -1}\n",
      "Score: 0.47660230730477754\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.400, R^2: 0.501, MBE: -0.002\n",
      "RMSE: 0.475, R^2: 0.430, MBE: 0.003\n",
      "RMSE: 0.478, R^2: 0.434, MBE: 0.013\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.7485763723465688, 'n_estimators': 475, 'n_jobs': -1}\n",
      "Score: 0.4508522226695078\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.440, R^2: 0.448, MBE: 0.026\n",
      "RMSE: 0.515, R^2: 0.373, MBE: -0.019\n",
      "RMSE: 0.450, R^2: 0.461, MBE: 0.010\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.1191163797834364, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4686794744841472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Sampling new data point ------\n",
      "RMSE: 0.458, R^2: 0.452, MBE: 0.004\n",
      "RMSE: 0.449, R^2: 0.457, MBE: 0.005\n",
      "RMSE: 0.454, R^2: 0.445, MBE: -0.013\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.1714531380329097, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.45351300146743556\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.385, R^2: 0.544, MBE: -0.027\n",
      "RMSE: 0.441, R^2: 0.468, MBE: 0.042\n",
      "RMSE: 0.508, R^2: 0.401, MBE: -0.014\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.2861850062191599, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4446446206533376\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.474, R^2: 0.388, MBE: 0.027\n",
      "RMSE: 0.458, R^2: 0.432, MBE: -0.018\n",
      "RMSE: 0.518, R^2: 0.394, MBE: -0.005\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.5552135266007312, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4835038132211138\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.399, R^2: 0.543, MBE: -0.009\n",
      "RMSE: 0.419, R^2: 0.485, MBE: 0.008\n",
      "RMSE: 0.524, R^2: 0.359, MBE: 0.004\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.6917537586047319, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.44749607968774213\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.413, R^2: 0.515, MBE: 0.015\n",
      "RMSE: 0.490, R^2: 0.406, MBE: 0.008\n",
      "RMSE: 0.452, R^2: 0.438, MBE: -0.018\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.7743964792907649, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.45181862866456246\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.434, R^2: 0.455, MBE: -0.012\n",
      "RMSE: 0.483, R^2: 0.413, MBE: 0.003\n",
      "RMSE: 0.482, R^2: 0.400, MBE: 0.015\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 1.0, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.46626698376148895\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.448, R^2: 0.482, MBE: -0.019\n",
      "RMSE: 0.410, R^2: 0.494, MBE: 0.031\n",
      "RMSE: 0.482, R^2: 0.416, MBE: -0.014\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.1645674008205729, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.44679727564071864\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.454, R^2: 0.466, MBE: -0.021\n",
      "RMSE: 0.469, R^2: 0.422, MBE: -0.012\n",
      "RMSE: 0.426, R^2: 0.486, MBE: 0.032\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 7, 'learning_rate': 0.7128497565632049, 'n_estimators': 127, 'n_jobs': -1}\n",
      "Score: 0.4499518567027309\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.440, R^2: 0.448, MBE: -0.015\n",
      "RMSE: 0.491, R^2: 0.410, MBE: 0.026\n",
      "RMSE: 0.456, R^2: 0.430, MBE: -0.014\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.6510099477638369, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4624467973843318\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.437, R^2: 0.473, MBE: 0.024\n",
      "RMSE: 0.420, R^2: 0.488, MBE: 0.001\n",
      "RMSE: 0.498, R^2: 0.396, MBE: -0.023\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.5643302957878796, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.45192985406716685\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.442, R^2: 0.461, MBE: -0.001\n",
      "RMSE: 0.445, R^2: 0.475, MBE: 0.022\n",
      "RMSE: 0.455, R^2: 0.451, MBE: -0.018\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.4378700480610989, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4473429576771082\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.391, R^2: 0.517, MBE: 0.011\n",
      "RMSE: 0.511, R^2: 0.399, MBE: 0.026\n",
      "RMSE: 0.475, R^2: 0.409, MBE: -0.047\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.12391482896611411, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.45886096727393816\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.419, R^2: 0.507, MBE: 0.003\n",
      "RMSE: 0.455, R^2: 0.462, MBE: 0.010\n",
      "RMSE: 0.464, R^2: 0.427, MBE: -0.013\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.2413398128959058, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4459548472178753\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.442, R^2: 0.441, MBE: -0.001\n",
      "RMSE: 0.444, R^2: 0.483, MBE: -0.027\n",
      "RMSE: 0.460, R^2: 0.456, MBE: 0.031\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.31271712539834895, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.44885060529779736\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.447, R^2: 0.462, MBE: -0.001\n",
      "RMSE: 0.449, R^2: 0.456, MBE: 0.014\n",
      "RMSE: 0.439, R^2: 0.485, MBE: -0.017\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.26809201220664897, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.44510880214618026\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.463, R^2: 0.435, MBE: -0.004\n",
      "RMSE: 0.468, R^2: 0.419, MBE: -0.021\n",
      "RMSE: 0.438, R^2: 0.478, MBE: 0.015\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.823926566768095, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4563190684911215\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.401, R^2: 0.492, MBE: 0.005\n",
      "RMSE: 0.498, R^2: 0.402, MBE: -0.025\n",
      "RMSE: 0.447, R^2: 0.489, MBE: 0.019\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.1316695986632925, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4483875094578343\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.435, R^2: 0.501, MBE: 0.009\n",
      "RMSE: 0.503, R^2: 0.392, MBE: 0.003\n",
      "RMSE: 0.401, R^2: 0.500, MBE: -0.017\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.4783092726691405, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.44636978894235807\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.489, R^2: 0.384, MBE: -0.008\n",
      "RMSE: 0.503, R^2: 0.378, MBE: 0.010\n",
      "RMSE: 0.508, R^2: 0.373, MBE: 0.028\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.5572478738183118, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.49980001796213297\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.448, R^2: 0.486, MBE: -0.016\n",
      "RMSE: 0.403, R^2: 0.503, MBE: -0.005\n",
      "RMSE: 0.484, R^2: 0.416, MBE: 0.025\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.17356815774602796, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.4450665432602355\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.491, R^2: 0.376, MBE: 0.007\n",
      "RMSE: 0.474, R^2: 0.406, MBE: 0.023\n",
      "RMSE: 0.490, R^2: 0.399, MBE: -0.027\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.2362903414039934, 'n_estimators': 125, 'n_jobs': -1}\n",
      "Score: 0.48513335955338666\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.431, R^2: 0.464, MBE: 0.010\n",
      "RMSE: 0.477, R^2: 0.414, MBE: -0.018\n",
      "RMSE: 0.467, R^2: 0.448, MBE: 0.012\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.1443509296967603, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 0.45803974477375053\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.424, R^2: 0.464, MBE: -0.006\n",
      "RMSE: 0.389, R^2: 0.538, MBE: -0.002\n",
      "RMSE: 0.531, R^2: 0.383, MBE: 0.013\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.31328511719828306, 'n_estimators': 493, 'n_jobs': -1}\n",
      "Score: 0.44799921068598403\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.477, R^2: 0.403, MBE: -0.022\n",
      "RMSE: 0.486, R^2: 0.412, MBE: 0.040\n",
      "RMSE: 0.473, R^2: 0.412, MBE: -0.018\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.14703259353941864, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.4786066170077304\n",
      "------ Sampling new data point ------\n",
      "RMSE: 0.427, R^2: 0.480, MBE: -0.015\n",
      "RMSE: 0.456, R^2: 0.442, MBE: 0.034\n",
      "RMSE: 0.489, R^2: 0.405, MBE: -0.010\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.39535457741527696, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 0.45698227958993537\n",
      "Optimal parameters\n",
      "Param: num_leaves, value: 2\n",
      "Param: objective, value: regression\n",
      "Param: min_data_in_leaf, value: 10\n",
      "Param: learning_rate, value: 0.2861850062191599\n",
      "Param: n_estimators, value: 100\n"
     ]
    }
   ],
   "source": [
    "for key in solvers_layer2:\n",
    "    label = f'val_Layer2_single_{key}'\n",
    "    val = deepcopy(model_library[key])\n",
    "    reg = val['model_instance']\n",
    "    params_space = val['params_space']\n",
    "\n",
    "\n",
    "    # Bayesian opt. part\n",
    "    @use_named_args(params_space)\n",
    "    def jth_objective(**params):\n",
    "        cls = reg.set_params(**params)\n",
    "        return utils.objective_core(cls, Xtrain_bothlayers, ytrain_bothlayers,\n",
    "                                    label, yscale,\n",
    "                                    nfolds=N_FOLDS, **params)\n",
    "\n",
    "\n",
    "    res = gp_minimize(jth_objective, params_space, n_calls=N_CALLS, random_state=0)\n",
    "    \"Best score=%.4f\" % res.fun\n",
    "\n",
    "    # Generating final optimized model instance\n",
    "    print(\"Optimal parameters\")\n",
    "    params = {}\n",
    "    for param, value in zip(params_space, res.x):\n",
    "        print(f\"Param: {param.name}, value: {value}\")\n",
    "        params[param.name] = value\n",
    "\n",
    "    jth_model = reg.set_params(**params)\n",
    "    jth_model.fit(Xtrain_bothlayers.values, ytrain_bothlayers.values)\n",
    "\n",
    "    # Model instance for ensemble\n",
    "    model_library[key]['model_instance_single'] = jth_model\n",
    "\n",
    "\n",
    "# Final SINGLE prediction on Xtest\n",
    "X_test = full_df.loc[test_filter, Xvar]\n",
    "y_test = full_df.loc[test_filter, yvar]\n",
    "\n",
    "# Prediction\n",
    "for key in solvers_layer2:\n",
    "    val = model_library[key]\n",
    "    cls = val[f'model_instance_single']\n",
    "    y_predicted_test = cls.predict(X_test)\n",
    "    full_df.loc[test_filter, yvar + f'_predicted_test_single_{key}'] =  y_predicted_test * ystd + ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a697a80f0>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, y_predicted_test,  '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with yvar = NAN removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [
     27
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3822, 5, 9) (3822,)\n",
      "Train on 1911 samples, validate on 1911 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 1.0553 - val_loss: 0.8907\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.8214 - val_loss: 0.8239\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.7427 - val_loss: 0.8080\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.7280 - val_loss: 0.7958\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.7113 - val_loss: 0.7851\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.6772 - val_loss: 0.7656\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.6433 - val_loss: 0.7529\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.6183 - val_loss: 0.7429\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.6363 - val_loss: 0.7376\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.6196 - val_loss: 0.7320\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.5995 - val_loss: 0.7224\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.6005 - val_loss: 0.7152\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.5948 - val_loss: 0.7046\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.5896 - val_loss: 0.7018\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.5862 - val_loss: 0.6947\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.5655 - val_loss: 0.6899\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.5710 - val_loss: 0.6880\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.5844 - val_loss: 0.6824\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.5600 - val_loss: 0.6801\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.5423 - val_loss: 0.6734\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.5541 - val_loss: 0.6714\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.5604 - val_loss: 0.6700\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.5544 - val_loss: 0.6734\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.5522 - val_loss: 0.6730\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.5407 - val_loss: 0.6678\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.5440 - val_loss: 0.6745\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.5171 - val_loss: 0.6733\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.5488 - val_loss: 0.6725\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.5290 - val_loss: 0.6699\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.5342 - val_loss: 0.6673\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.5404 - val_loss: 0.6676\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.5428 - val_loss: 0.6725\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.5246 - val_loss: 0.6713\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.5405 - val_loss: 0.6749\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.5374 - val_loss: 0.6714\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.5301 - val_loss: 0.6685\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.5289 - val_loss: 0.6696\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.5402 - val_loss: 0.6782\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.5192 - val_loss: 0.6800\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.5280 - val_loss: 0.6864\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.5049 - val_loss: 0.6748\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.5143 - val_loss: 0.6766\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.5126 - val_loss: 0.6791\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.5175 - val_loss: 0.6724\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.5163 - val_loss: 0.6735\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.5157 - val_loss: 0.6767\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.4933 - val_loss: 0.6808\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.5012 - val_loss: 0.6771\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.5128 - val_loss: 0.6760\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.5089 - val_loss: 0.6805\n",
      "RMSE: 2.944, R^2: 0.386, MBE: 0.456\n"
     ]
    }
   ],
   "source": [
    "# LSTM -- Single\n",
    "NSTEPS = 5\n",
    "NFEATURES = Xtrain_bothlayers.shape[1]\n",
    "\n",
    "# convert into input/output sequences\n",
    "dataset_train = np.column_stack((Xtrain_bothlayers, ytrain_bothlayers))\n",
    "dataset_trainX, dataset_trainy = utils.split_sequences(dataset_train, NSTEPS)\n",
    "print(dataset_trainX.shape, dataset_trainy.shape)\n",
    "\n",
    "# define model\n",
    "model_lstm = Sequential()\n",
    "#model_lstm.add(LSTM(5, input_shape=(NSTEPS, NFEATURES), activation='relu', dropout=0.5, recurrent_dropout=0.5))\n",
    "model_lstm.add(Bidirectional(LSTM(5, input_shape=(NSTEPS, NFEATURES), activation='relu', dropout=0.5, recurrent_dropout=0.5)))\n",
    "#model_lstm.add(Dense(3, kernel_initializer='normal', activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='linear'))\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model_lstm.fit(dataset_trainX, dataset_trainy,\n",
    "                            validation_split=0.5, shuffle=False,\n",
    "                            epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "dataset_test = np.column_stack((X_test, y_test))\n",
    "dataset_testX, dataset_testy = utils.split_sequences(dataset_test, n_steps=NSTEPS)\n",
    "yhat_test = model_lstm.predict(dataset_testX, verbose=0)\n",
    "\n",
    "metric_lstm = utils.diagnostic_stats(dataset_testy*ystd + ymean,\n",
    "                                     yhat_test.squeeze()*ystd + ymean)\n",
    "\n",
    "yhat_test = np.concatenate((np.array([np.nan]*(NSTEPS-1)), yhat_test.squeeze()))\n",
    "\n",
    "full_df.loc[test_filter,\n",
    "            yvar + f'_predicted_test_single_LSTM'] = yhat_test * ystd + ymean\n",
    "\n",
    "utils.SCORES['Layer2' + '_' + 'LSTM' + '_' + 'single'] = {'rmse':metric_lstm[0],\n",
    "                                                          'rsqr':metric_lstm[1],\n",
    "                                                          'mbe':metric_lstm[2],\n",
    "                                                          'corr':metric_lstm[3],\n",
    "                                                          'stddev':metric_lstm[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2 LGBM single\n",
      "RMSE: 2.938, R^2: 0.398, MBE: 0.586\n"
     ]
    }
   ],
   "source": [
    "# ---------- Summary stats -------------------\n",
    "ytest = full_df.loc[test_filter, yvar] * ystd + ymean\n",
    "\n",
    "for key in solvers_layer2:\n",
    "    for j in ['single']:\n",
    "        ytest_predicted = full_df.loc[test_filter, yvar + f'_predicted_test_{j}_{key}']\n",
    "\n",
    "        print('Layer2', key, j)\n",
    "        ametric = utils.diagnostic_stats(ytest, ytest_predicted)\n",
    "        #print(ascore)\n",
    "        all_scores = {}\n",
    "        for k, metric_name in enumerate(['rmse', 'rsqr', 'mbe', 'corr', 'stddev']):\n",
    "            all_scores[metric_name] = ametric[k]\n",
    "\n",
    "        utils.SCORES['Layer2' + '_' + key + '_' + j] = all_scores\n",
    "\n",
    "score_df = pd.DataFrame.from_dict(utils.SCORES).T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_Layer2_single_LGBM</th>\n",
       "      <td>0.457</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LSTM_single</th>\n",
       "      <td>2.944</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.621</td>\n",
       "      <td>2.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LGBM_single</th>\n",
       "      <td>2.938</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.631</td>\n",
       "      <td>2.550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rmse   rsqr    mbe   corr  stddev\n",
       "val_Layer2_single_LGBM  0.457  0.442  0.003  0.665   0.435\n",
       "Layer2_LSTM_single      2.944  0.386  0.456  0.621   2.462\n",
       "Layer2_LGBM_single      2.938  0.398  0.586  0.631   2.550"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_Layer2_single_LGBM</th>\n",
       "      <td>0.457</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LSTM_single</th>\n",
       "      <td>2.944</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.621</td>\n",
       "      <td>2.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LGBM_single</th>\n",
       "      <td>2.938</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.631</td>\n",
       "      <td>2.550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rmse   rsqr    mbe   corr  stddev\n",
       "val_Layer2_single_LGBM  0.457  0.442  0.003  0.665   0.435\n",
       "Layer2_LSTM_single      2.944  0.386  0.455  0.621   2.460\n",
       "Layer2_LGBM_single      2.938  0.398  0.586  0.631   2.550"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE with -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Single model run ------\n",
    "Xtrain_bothlayers = full_df.loc[(full_df['Set_rank'] != 'test'), Xvar]\n",
    "ytrain_bothlayers = full_df.loc[(full_df['Set_rank'] != 'test'), yvar].fillna(-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading model, total used 100 iterations\n",
      "------ Sampling new data point ------\n",
      "RMSE: 14.646, R^2: 0.756, MBE: 0.057\n",
      "RMSE: 14.913, R^2: 0.739, MBE: -0.113\n",
      "RMSE: 14.874, R^2: 0.750, MBE: 0.129\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.8472670136102473, 'n_estimators': 349, 'n_jobs': -1}\n",
      "Score: 14.81112242424991\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.665, R^2: 0.806, MBE: -0.101\n",
      "RMSE: 12.353, R^2: 0.814, MBE: 0.190\n",
      "RMSE: 13.198, R^2: 0.791, MBE: -0.253\n",
      "Params: {'num_leaves': 5, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.27272902895065526, 'n_estimators': 291, 'n_jobs': -1}\n",
      "Score: 12.738494100851186\n",
      "------ Sampling new data point ------\n",
      "RMSE: 15.553, R^2: 0.718, MBE: 0.612\n",
      "RMSE: 14.773, R^2: 0.751, MBE: 0.610\n",
      "RMSE: 14.625, R^2: 0.755, MBE: -0.498\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.836095155661024, 'n_estimators': 235, 'n_jobs': -1}\n",
      "Score: 14.983817494834755\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.782, R^2: 0.803, MBE: 0.399\n",
      "RMSE: 11.851, R^2: 0.831, MBE: 0.076\n",
      "RMSE: 11.768, R^2: 0.830, MBE: -0.448\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.1404367453346039, 'n_estimators': 448, 'n_jobs': -1}\n",
      "Score: 12.133757781693218\n",
      "------ Sampling new data point ------\n",
      "RMSE: 14.291, R^2: 0.762, MBE: 0.553\n",
      "RMSE: 13.529, R^2: 0.783, MBE: -0.288\n",
      "RMSE: 13.931, R^2: 0.770, MBE: -0.188\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 6, 'learning_rate': 0.6789116421659485, 'n_estimators': 388, 'n_jobs': -1}\n",
      "Score: 13.916787787474988\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.777, R^2: 0.803, MBE: -0.116\n",
      "RMSE: 12.162, R^2: 0.819, MBE: -0.169\n",
      "RMSE: 12.291, R^2: 0.817, MBE: 0.527\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.10599701642707338, 'n_estimators': 289, 'n_jobs': -1}\n",
      "Score: 12.40986808183368\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.559, R^2: 0.775, MBE: -0.551\n",
      "RMSE: 13.509, R^2: 0.784, MBE: 0.152\n",
      "RMSE: 13.565, R^2: 0.776, MBE: 0.464\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.13530465158811153, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 13.544122458931943\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.657, R^2: 0.778, MBE: 0.349\n",
      "RMSE: 13.641, R^2: 0.777, MBE: -0.402\n",
      "RMSE: 13.793, R^2: 0.772, MBE: -0.113\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 5, 'learning_rate': 0.9026082156818519, 'n_estimators': 280, 'n_jobs': -1}\n",
      "Score: 13.696930549106925\n",
      "------ Sampling new data point ------\n",
      "RMSE: 16.510, R^2: 0.700, MBE: 0.136\n",
      "RMSE: 15.848, R^2: 0.721, MBE: -0.051\n",
      "RMSE: 16.414, R^2: 0.701, MBE: 0.141\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.9698120868399743, 'n_estimators': 361, 'n_jobs': -1}\n",
      "Score: 16.257465415685747\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.277, R^2: 0.785, MBE: -0.403\n",
      "RMSE: 12.634, R^2: 0.806, MBE: 0.306\n",
      "RMSE: 13.501, R^2: 0.783, MBE: 0.217\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 8, 'learning_rate': 0.6078698856485963, 'n_estimators': 230, 'n_jobs': -1}\n",
      "Score: 13.137408526934392\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.886, R^2: 0.800, MBE: 0.147\n",
      "RMSE: 11.636, R^2: 0.836, MBE: -0.016\n",
      "RMSE: 11.856, R^2: 0.830, MBE: -0.723\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.22262087558472285, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.126215498219137\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.327, R^2: 0.811, MBE: -0.579\n",
      "RMSE: 12.263, R^2: 0.818, MBE: 0.334\n",
      "RMSE: 12.506, R^2: 0.815, MBE: -0.058\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.17692592841002594, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.365328418338036\n",
      "------ Sampling new data point ------\n",
      "RMSE: 11.472, R^2: 0.840, MBE: 0.074\n",
      "RMSE: 12.048, R^2: 0.821, MBE: -0.300\n",
      "RMSE: 12.860, R^2: 0.804, MBE: 0.314\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.12739673305465254, 'n_estimators': 480, 'n_jobs': -1}\n",
      "Score: 12.126348123981607\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.613, R^2: 0.808, MBE: 0.103\n",
      "RMSE: 12.179, R^2: 0.822, MBE: -0.101\n",
      "RMSE: 12.258, R^2: 0.816, MBE: -0.139\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.19341048908901373, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.350077859257887\n",
      "------ Sampling new data point ------\n",
      "RMSE: 14.763, R^2: 0.764, MBE: -0.071\n",
      "RMSE: 14.197, R^2: 0.789, MBE: -0.348\n",
      "RMSE: 15.539, R^2: 0.736, MBE: 0.528\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0034961643668690637, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 14.832863725920982\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.098, R^2: 0.794, MBE: -0.363\n",
      "RMSE: 12.661, R^2: 0.808, MBE: 0.126\n",
      "RMSE: 12.178, R^2: 0.822, MBE: 0.047\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.2794330061900333, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.645570574463248\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.041, R^2: 0.828, MBE: 0.723\n",
      "RMSE: 12.016, R^2: 0.823, MBE: -0.082\n",
      "RMSE: 12.752, R^2: 0.803, MBE: -0.595\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.13627400928260644, 'n_estimators': 454, 'n_jobs': -1}\n",
      "Score: 12.269519387369265\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.749, R^2: 0.806, MBE: 0.735\n",
      "RMSE: 12.989, R^2: 0.796, MBE: -0.488\n",
      "RMSE: 12.192, R^2: 0.818, MBE: -0.120\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.14071330916183583, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.643097198372436\n",
      "------ Sampling new data point ------\n",
      "RMSE: 11.916, R^2: 0.831, MBE: -0.435\n",
      "RMSE: 13.452, R^2: 0.781, MBE: 0.614\n",
      "RMSE: 12.494, R^2: 0.809, MBE: -0.079\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.24286288609318082, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.620858233382876\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.176, R^2: 0.817, MBE: -0.476\n",
      "RMSE: 12.516, R^2: 0.810, MBE: -0.249\n",
      "RMSE: 12.795, R^2: 0.807, MBE: 0.203\n",
      "Params: {'num_leaves': 9, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.14971868993298723, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.495749135131717\n",
      "------ Sampling new data point ------\n",
      "RMSE: 15.932, R^2: 0.698, MBE: -0.233\n",
      "RMSE: 14.468, R^2: 0.744, MBE: 0.179\n",
      "RMSE: 15.052, R^2: 0.724, MBE: -0.077\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.43509190562278327, 'n_estimators': 482, 'n_jobs': -1}\n",
      "Score: 15.150775172918637\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.913, R^2: 0.799, MBE: 0.376\n",
      "RMSE: 12.678, R^2: 0.803, MBE: -0.105\n",
      "RMSE: 13.339, R^2: 0.786, MBE: -0.441\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.2025994710554384, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.97657628787096\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.203, R^2: 0.819, MBE: -0.155\n",
      "RMSE: 12.230, R^2: 0.816, MBE: -0.483\n",
      "RMSE: 11.997, R^2: 0.830, MBE: 0.721\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.12297313235086506, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.143224247119852\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.476, R^2: 0.811, MBE: -0.001\n",
      "RMSE: 12.474, R^2: 0.815, MBE: 0.095\n",
      "RMSE: 12.085, R^2: 0.820, MBE: -0.014\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.12062000642383768, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.345173486435158\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.540, R^2: 0.813, MBE: 0.726\n",
      "RMSE: 11.639, R^2: 0.832, MBE: -0.336\n",
      "RMSE: 12.774, R^2: 0.804, MBE: -0.241\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.13031402697386094, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.317549950335485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Sampling new data point ------\n",
      "RMSE: 13.124, R^2: 0.794, MBE: 0.451\n",
      "RMSE: 11.567, R^2: 0.837, MBE: -0.307\n",
      "RMSE: 11.967, R^2: 0.828, MBE: -0.207\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.21738140108138854, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.219510425019507\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.386, R^2: 0.817, MBE: -0.172\n",
      "RMSE: 12.348, R^2: 0.813, MBE: 0.419\n",
      "RMSE: 11.702, R^2: 0.834, MBE: 0.182\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.1210757098253665, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.1452858689052\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.761, R^2: 0.805, MBE: -0.286\n",
      "RMSE: 12.639, R^2: 0.806, MBE: 0.056\n",
      "RMSE: 12.578, R^2: 0.808, MBE: 0.219\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.11537202609750248, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.659437213960532\n",
      "------ Sampling new data point ------\n",
      "RMSE: 11.484, R^2: 0.843, MBE: 0.082\n",
      "RMSE: 13.116, R^2: 0.790, MBE: -0.605\n",
      "RMSE: 12.632, R^2: 0.807, MBE: 0.049\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.174952416775241, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.410646359286575\n",
      "------ Sampling new data point ------\n",
      "RMSE: 15.467, R^2: 0.721, MBE: 1.056\n",
      "RMSE: 15.716, R^2: 0.699, MBE: -0.634\n",
      "RMSE: 16.398, R^2: 0.668, MBE: -0.937\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.7717265793105526, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 15.86004202542135\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.623, R^2: 0.782, MBE: 0.517\n",
      "RMSE: 13.457, R^2: 0.790, MBE: -0.325\n",
      "RMSE: 13.816, R^2: 0.771, MBE: -0.038\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 4, 'learning_rate': 0.5898026339215876, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 13.631989663281232\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.195, R^2: 0.818, MBE: -0.242\n",
      "RMSE: 12.646, R^2: 0.808, MBE: -0.261\n",
      "RMSE: 13.013, R^2: 0.799, MBE: 0.244\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.22469938513331647, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.617992745169873\n",
      "------ Sampling new data point ------\n",
      "RMSE: 14.793, R^2: 0.734, MBE: 0.149\n",
      "RMSE: 16.022, R^2: 0.691, MBE: -0.371\n",
      "RMSE: 14.940, R^2: 0.729, MBE: 0.153\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.24087708505322497, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 15.251674429084881\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.364, R^2: 0.816, MBE: 0.141\n",
      "RMSE: 12.750, R^2: 0.804, MBE: 0.173\n",
      "RMSE: 13.200, R^2: 0.790, MBE: -0.161\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 3, 'learning_rate': 0.30722405822247156, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.771293085494525\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.121, R^2: 0.818, MBE: -0.128\n",
      "RMSE: 12.161, R^2: 0.825, MBE: -0.147\n",
      "RMSE: 13.253, R^2: 0.786, MBE: 0.231\n",
      "Params: {'num_leaves': 7, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.12894935204819427, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.51167322991332\n",
      "------ Sampling new data point ------\n",
      "RMSE: 28.520, R^2: 0.280, MBE: 0.875\n",
      "RMSE: 28.234, R^2: 0.299, MBE: -0.344\n",
      "RMSE: 28.165, R^2: 0.324, MBE: -0.532\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.0001, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 28.306565847263613\n",
      "------ Sampling new data point ------\n",
      "RMSE: 11.307, R^2: 0.845, MBE: -0.232\n",
      "RMSE: 12.376, R^2: 0.814, MBE: 0.158\n",
      "RMSE: 12.462, R^2: 0.813, MBE: 0.060\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0910478973974011, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.048363573245405\n",
      "------ Sampling new data point ------\n",
      "RMSE: 11.884, R^2: 0.829, MBE: -0.150\n",
      "RMSE: 12.149, R^2: 0.818, MBE: -0.123\n",
      "RMSE: 11.745, R^2: 0.835, MBE: 0.117\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0872621163130894, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 11.925811401958702\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.256, R^2: 0.818, MBE: 0.052\n",
      "RMSE: 12.024, R^2: 0.824, MBE: 0.200\n",
      "RMSE: 12.311, R^2: 0.817, MBE: -0.330\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.08093821873407127, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.196644079792756\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.312, R^2: 0.816, MBE: -0.363\n",
      "RMSE: 13.208, R^2: 0.797, MBE: 0.046\n",
      "RMSE: 12.510, R^2: 0.812, MBE: 0.330\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.4423572451689487, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.67658047145604\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.733, R^2: 0.805, MBE: -0.432\n",
      "RMSE: 12.715, R^2: 0.807, MBE: 0.537\n",
      "RMSE: 12.560, R^2: 0.809, MBE: 0.198\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.3780225644520606, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 12.669251449686106\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.701, R^2: 0.779, MBE: -0.077\n",
      "RMSE: 12.942, R^2: 0.797, MBE: -0.268\n",
      "RMSE: 13.358, R^2: 0.787, MBE: 0.261\n",
      "Params: {'num_leaves': 6, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.535207807598307, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 13.333576395641716\n",
      "------ Sampling new data point ------\n",
      "RMSE: 15.095, R^2: 0.726, MBE: 0.077\n",
      "RMSE: 14.892, R^2: 0.732, MBE: 0.330\n",
      "RMSE: 15.129, R^2: 0.721, MBE: -0.600\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 1.0, 'n_estimators': 500, 'n_jobs': -1}\n",
      "Score: 15.038525933057949\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.736, R^2: 0.800, MBE: 0.008\n",
      "RMSE: 13.573, R^2: 0.777, MBE: 0.198\n",
      "RMSE: 13.164, R^2: 0.794, MBE: -0.312\n",
      "Params: {'num_leaves': 4, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.20873663497610445, 'n_estimators': 116, 'n_jobs': -1}\n",
      "Score: 13.157648686297998\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.063, R^2: 0.820, MBE: 0.225\n",
      "RMSE: 13.633, R^2: 0.777, MBE: 0.270\n",
      "RMSE: 12.787, R^2: 0.805, MBE: -0.582\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.0870916536000097, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.827394833418682\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.554, R^2: 0.781, MBE: 0.690\n",
      "RMSE: 12.741, R^2: 0.804, MBE: 0.069\n",
      "RMSE: 12.696, R^2: 0.805, MBE: -0.678\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.413367350294877, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.99703952333092\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.193, R^2: 0.788, MBE: 0.338\n",
      "RMSE: 13.992, R^2: 0.766, MBE: 0.178\n",
      "RMSE: 13.751, R^2: 0.770, MBE: -0.377\n",
      "Params: {'num_leaves': 3, 'objective': 'regression', 'min_data_in_leaf': 9, 'learning_rate': 0.24435034171645414, 'n_estimators': 159, 'n_jobs': -1}\n",
      "Score: 13.645670879753125\n",
      "------ Sampling new data point ------\n",
      "RMSE: 13.356, R^2: 0.787, MBE: -0.436\n",
      "RMSE: 12.610, R^2: 0.810, MBE: 0.180\n",
      "RMSE: 12.733, R^2: 0.803, MBE: 0.016\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.4998624147610172, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.899902901299143\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.812, R^2: 0.805, MBE: 0.912\n",
      "RMSE: 11.842, R^2: 0.828, MBE: -0.484\n",
      "RMSE: 12.082, R^2: 0.823, MBE: -0.300\n",
      "Params: {'num_leaves': 8, 'objective': 'regression', 'min_data_in_leaf': 10, 'learning_rate': 0.27509151997108233, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.24519855349891\n",
      "------ Sampling new data point ------\n",
      "RMSE: 12.829, R^2: 0.802, MBE: -0.508\n",
      "RMSE: 13.172, R^2: 0.791, MBE: 0.216\n",
      "RMSE: 12.306, R^2: 0.816, MBE: 0.026\n",
      "Params: {'num_leaves': 10, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.33705021157992815, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 12.769218798679413\n",
      "------ Sampling new data point ------\n",
      "RMSE: 15.452, R^2: 0.709, MBE: -0.560\n",
      "RMSE: 15.898, R^2: 0.697, MBE: 0.156\n",
      "RMSE: 15.752, R^2: 0.698, MBE: 0.380\n",
      "Params: {'num_leaves': 2, 'objective': 'regression', 'min_data_in_leaf': 2, 'learning_rate': 0.5493285875259488, 'n_estimators': 100, 'n_jobs': -1}\n",
      "Score: 15.701014949128627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal parameters\n",
      "Param: num_leaves, value: 10\n",
      "Param: objective, value: regression\n",
      "Param: min_data_in_leaf, value: 10\n",
      "Param: learning_rate, value: 0.0872621163130894\n",
      "Param: n_estimators, value: 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in solvers_layer2:\n",
    "    label = f'val_Layer2_single_{key}'\n",
    "    val = deepcopy(model_library[key])\n",
    "    reg = val['model_instance']\n",
    "    params_space = val['params_space']\n",
    "\n",
    "\n",
    "    # Bayesian opt. part\n",
    "    @use_named_args(params_space)\n",
    "    def jth_objective(**params):\n",
    "        cls = reg.set_params(**params)\n",
    "        return utils.objective_core(cls, Xtrain_bothlayers, ytrain_bothlayers,\n",
    "                                    label, yscale,\n",
    "                                    nfolds=N_FOLDS, **params)\n",
    "\n",
    "\n",
    "    res = gp_minimize(jth_objective, params_space, n_calls=N_CALLS, random_state=0)\n",
    "    \"Best score=%.4f\" % res.fun\n",
    "\n",
    "    # Generating final optimized model instance\n",
    "    print(\"Optimal parameters\")\n",
    "    params = {}\n",
    "    for param, value in zip(params_space, res.x):\n",
    "        print(f\"Param: {param.name}, value: {value}\")\n",
    "        params[param.name] = value\n",
    "\n",
    "    jth_model = reg.set_params(**params)\n",
    "    jth_model.fit(Xtrain_bothlayers.values, ytrain_bothlayers.values)\n",
    "\n",
    "    # Model instance for ensemble\n",
    "    model_library[key]['model_instance_single'] = jth_model\n",
    "\n",
    "\n",
    "# Final SINGLE prediction on Xtest\n",
    "X_test = full_df.loc[test_filter, Xvar]\n",
    "y_test = full_df.loc[test_filter, yvar]\n",
    "\n",
    "# Prediction\n",
    "for key in solvers_layer2:\n",
    "    val = model_library[key]\n",
    "    cls = val[f'model_instance_single']\n",
    "    y_predicted_test = cls.predict(X_test)\n",
    "    full_df.loc[test_filter, yvar + f'_predicted_test_single_{key}'] =  y_predicted_test * ystd + ymean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a60fa62b0>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test, y_predicted_test,  '.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystd2, ymean2 = ytrain_bothlayers.std(), ytrain_bothlayers.mean()\n",
    "ytrain_bothlayers = (ytrain_bothlayers - ymean2)/ystd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5803, 5, 9) (5803,)\n",
      "Train on 2901 samples, validate on 2902 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 5.1668 - val_loss: 0.9115\n",
      "Epoch 2/50\n",
      " - 1s - loss: 2.8968 - val_loss: 0.8765\n",
      "Epoch 3/50\n",
      " - 1s - loss: 1.9185 - val_loss: 0.8662\n",
      "Epoch 4/50\n",
      " - 1s - loss: 1.4612 - val_loss: 0.8673\n",
      "Epoch 5/50\n",
      " - 1s - loss: 1.2823 - val_loss: 0.8690\n",
      "Epoch 6/50\n",
      " - 1s - loss: 1.1490 - val_loss: 0.8706\n",
      "Epoch 7/50\n",
      " - 1s - loss: 1.0958 - val_loss: 0.8706\n",
      "Epoch 8/50\n",
      " - 1s - loss: 1.0319 - val_loss: 0.8688\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.9848 - val_loss: 0.8637\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.9522 - val_loss: 0.8585\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.9595 - val_loss: 0.8534\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.9397 - val_loss: 0.8460\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.9281 - val_loss: 0.8390\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.9018 - val_loss: 0.8321\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.8912 - val_loss: 0.8247\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.9035 - val_loss: 0.8175\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.8747 - val_loss: 0.8105\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.8953 - val_loss: 0.8046\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.8816 - val_loss: 0.8007\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.8449 - val_loss: 0.7900\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.8601 - val_loss: 0.7868\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.8442 - val_loss: 0.7809\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.8506 - val_loss: 0.7789\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.8372 - val_loss: 0.7748\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.8388 - val_loss: 0.7697\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.8202 - val_loss: 0.7705\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.8280 - val_loss: 0.7676\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.8257 - val_loss: 0.7650\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.8204 - val_loss: 0.7603\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.8219 - val_loss: 0.7585\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.8139 - val_loss: 0.7531\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.8123 - val_loss: 0.7542\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.8103 - val_loss: 0.7479\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.8076 - val_loss: 0.7447\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.8004 - val_loss: 0.7402\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.8133 - val_loss: 0.7343\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.7982 - val_loss: 0.7309\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.8045 - val_loss: 0.7294\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.8014 - val_loss: 0.7302\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.7979 - val_loss: 0.7300\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.7819 - val_loss: 0.7232\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.7993 - val_loss: 0.7105\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.8045 - val_loss: 0.7144\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.7824 - val_loss: 0.7116\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.7832 - val_loss: 0.7081\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.7805 - val_loss: 0.7076\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.7766 - val_loss: 0.7072\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.7725 - val_loss: 0.7030\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.7783 - val_loss: 0.6961\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.7732 - val_loss: 0.6943\n",
      "RMSE: 53.046, R^2: 0.022, MBE: 19.152\n"
     ]
    }
   ],
   "source": [
    "# LSTM -- Single\n",
    "NSTEPS = 5\n",
    "NFEATURES = Xtrain_bothlayers.shape[1]\n",
    "\n",
    "# convert into input/output sequences\n",
    "dataset_train = np.column_stack((Xtrain_bothlayers, ytrain_bothlayers))\n",
    "dataset_trainX, dataset_trainy = utils.split_sequences(dataset_train, NSTEPS)\n",
    "print(dataset_trainX.shape, dataset_trainy.shape)\n",
    "\n",
    "# define model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(5, input_shape=(NSTEPS, NFEATURES), activation='relu', dropout=0.5, recurrent_dropout=0.5))\n",
    "#model_lstm.add(Dense(3, kernel_initializer='normal', activation='relu'))\n",
    "model_lstm.add(Dense(1, activation='linear'))\n",
    "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "history = model_lstm.fit(dataset_trainX, dataset_trainy,\n",
    "                            validation_split=0.5, shuffle=False,\n",
    "                            epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "dataset_test = np.column_stack((X_test, y_test))\n",
    "dataset_testX, dataset_testy = utils.split_sequences(dataset_test, n_steps=NSTEPS)\n",
    "yhat_test = model_lstm.predict(dataset_testX, verbose=0)\n",
    "\n",
    "metric_lstm = utils.diagnostic_stats(dataset_testy*ystd + ymean,\n",
    "                                     yhat_test.squeeze()*ystd + ymean)\n",
    "\n",
    "yhat_test = np.concatenate((np.array([np.nan]*(NSTEPS-1)), yhat_test.squeeze()))\n",
    "\n",
    "full_df.loc[test_filter,\n",
    "            yvar + f'_predicted_test_single_LSTM'] = yhat_test * ystd + ymean\n",
    "\n",
    "utils.SCORES['Layer2' + '_' + 'LSTM' + '_' + 'single'] = {'rmse':metric_lstm[0],\n",
    "                                                          'rsqr':metric_lstm[1],\n",
    "                                                          'mbe':metric_lstm[2],\n",
    "                                                          'corr':metric_lstm[3],\n",
    "                                                          'stddev':metric_lstm[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBM']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solvers_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer2 LGBM single\n",
      "RMSE: 1077.309, R^2: 0.016, MBE: 561.186\n"
     ]
    }
   ],
   "source": [
    "# ---------- Summary stats -------------------\n",
    "ytest = full_df.loc[test_filter, yvar] * ystd + ymean\n",
    "\n",
    "for key in solvers_layer2:\n",
    "    for j in ['single']:\n",
    "        ytest_predicted = full_df.loc[test_filter, yvar + f'_predicted_test_{j}_{key}']\n",
    "\n",
    "        print('Layer2', key, j)\n",
    "        ametric = utils.diagnostic_stats(ytest, ytest_predicted)\n",
    "        #print(ascore)\n",
    "        all_scores = {}\n",
    "        for k, metric_name in enumerate(['rmse', 'rsqr', 'mbe', 'corr', 'stddev']):\n",
    "            all_scores[metric_name] = ametric[k]\n",
    "\n",
    "        utils.SCORES['Layer2' + '_' + key + '_' + j] = all_scores\n",
    "\n",
    "score_df2 = pd.DataFrame.from_dict(utils.SCORES).T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_Layer2_single_LGBM</th>\n",
       "      <td>15.701</td>\n",
       "      <td>0.701</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.838</td>\n",
       "      <td>23.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LSTM_single</th>\n",
       "      <td>53.046</td>\n",
       "      <td>0.022</td>\n",
       "      <td>19.152</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>9.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LGBM_single</th>\n",
       "      <td>1077.309</td>\n",
       "      <td>0.016</td>\n",
       "      <td>561.186</td>\n",
       "      <td>-0.126</td>\n",
       "      <td>912.497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            rmse   rsqr      mbe   corr   stddev\n",
       "val_Layer2_single_LGBM    15.701  0.701   -0.008  0.838   23.832\n",
       "Layer2_LSTM_single        53.046  0.022   19.152 -0.148    9.553\n",
       "Layer2_LGBM_single      1077.309  0.016  561.186 -0.126  912.497"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With -10\n",
    "score_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>rsqr</th>\n",
       "      <th>mbe</th>\n",
       "      <th>corr</th>\n",
       "      <th>stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>val_Layer2_single_LGBM</th>\n",
       "      <td>0.447</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LSTM_single</th>\n",
       "      <td>3.002</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.603</td>\n",
       "      <td>1.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer2_LGBM_single</th>\n",
       "      <td>2.947</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.631</td>\n",
       "      <td>2.560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         rmse   rsqr    mbe   corr  stddev\n",
       "val_Layer2_single_LGBM  0.447  0.465  0.000  0.682   0.409\n",
       "Layer2_LSTM_single      3.002  0.364  0.402  0.603   1.911\n",
       "Layer2_LGBM_single      2.947  0.398  0.622  0.631   2.560"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with nan removed\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
